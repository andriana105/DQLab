{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame & Series\n",
    "\n",
    "Di Pandas terdapat 2 kelas data baru yang digunakan sebagai struktur dari spreadsheet:\n",
    "\n",
    "1. Series: satu kolom bagian dari tabel dataframe yang merupakan 1 dimensional numpy array sebagai basis data nya, terdiri dari 1 tipe data (integer, string, float, dll).\n",
    "2. DataFrame: gabungan dari Series, berbentuk rectangular data yang merupakan tabel spreadsheet itu sendiri (karena dibentuk dari banyak Series, tiap Series biasanya punya 1 tipe data, yang artinya 1 dataframe bisa memiliki banyak tipe data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n",
      "DataFrame:\n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "2  3  4  5\n",
      "3  d  4  6\n"
     ]
    }
   ],
   "source": [
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "print(\"Series:\")\n",
    "print(number_list)\n",
    "\n",
    "# DataFrame\n",
    "matrix = [[1,2,3],\n",
    "          ['a','b','c'],\n",
    "          [3,4,5],\n",
    "          ['d',4,6]]\n",
    "matrix_list = pd.DataFrame(matrix)\n",
    "print(\"DataFrame:\")\n",
    "print(matrix_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 1\n",
    "Dataframe dan Series memiliki sangat banyak atribut yang digunakan untuk transformasi data, tetapi ada beberapa attribute yang sering dipakai. Di sini series number_list dan data frame matrix_list pada subbab sebelumnya digunakan kembali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Attribute .info()\n",
    "\n",
    "Attribute .info() digunakan untuk mengecek kolom apa yang membentuk dataframe itu, data types, berapa yang non null, dll. Attribute ini tidak dapat digunakan pada series, hanya pada data frame saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] atribute .info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       4 non-null      object\n",
      " 1   1       4 non-null      object\n",
      " 2   2       4 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 224.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"[1] atribute .info()\")\n",
    "print(matrix_list.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Attribute .shape\n",
    "\n",
    "Attribute .shape digunakan untuk mengetahui berapa baris dan kolom, hasilnya dalam format tuple (baris, kolom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] attribute .shape\n",
      "    Shape dari number_list: (6,)\n",
      "    Shape dari matrix_list: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "# [2] attribute .shape\n",
    "# [2] attribute .shape\n",
    "print(\"\\n[2] attribute .shape\")\n",
    "print(\"    Shape dari number_list:\", number_list.shape)\n",
    "print(\"    Shape dari matrix_list:\", matrix_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Attribute .dtypes\n",
    "\n",
    "Attribute .dtypes digunakan untuk mengetahui tipe data di tiap kolom. Tipe data object: kombinasi untuk berbagai tipe data (number & text, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] attribute .dtypes\n",
      "    Tipe data number_list: int64\n",
      "    Tipe data matrix_list: 0    object\n",
      "1    object\n",
      "2    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# [3] attribute .dtypes\n",
    "print(\"\\n[3] attribute .dtypes\")\n",
    "print(\"    Tipe data number_list:\", number_list.dtypes)\n",
    "print(\"    Tipe data matrix_list:\", matrix_list.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Attribute .astype(nama_tipe_data)\n",
    "\n",
    "Attribute .astype(nama_tipe_data) untuk convert tipe data berdasarkan tipe data seperti: float, int, str, numpy.float, numpy.int ataupun numpy.datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] attribute .astype()\n",
      "    Konversi number_list ke str: 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: object\n",
      "    Konversi matrix_list ke str:    0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "2  3  4  5\n",
      "3  d  4  6\n"
     ]
    }
   ],
   "source": [
    "# [4] attribute .astype()\n",
    "print(\"\\n[4] attribute .astype()\")\n",
    "print(\"    Konversi number_list ke str:\", number_list.astype(\"str\"))\n",
    "print(\"    Konversi matrix_list ke str:\", matrix_list.astype(\"str\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Attribute .copy()\n",
    "\n",
    "Attribute .copy() digunakan melakukan duplikat, untuk disimpan di variable yang berbeda mungkin supaya tidak loading data lagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] attribute .copy()\n",
      "    Copy number_list ke num_list: 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n",
      "    Copy matrix_list ke mtr_list:    0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "2  3  4  5\n",
      "3  d  4  6\n"
     ]
    }
   ],
   "source": [
    "# [5] attribute .copy()\n",
    "print(\"[5] attribute .copy()\")\n",
    "num_list = number_list.copy()\n",
    "print(\"    Copy number_list ke num_list:\", num_list)\n",
    "mtr_list = matrix_list.copy()\n",
    "print(\"    Copy matrix_list ke mtr_list:\", mtr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Attribute .to_list()\n",
    "\n",
    "Attribute .to_list() digunakan untuk mengubah series menjadi list dan tidak dapat digunakan untuk dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] attribute .to_list()\n",
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "# [6] attribute .to_list()\n",
    "print(\"[6] attribute .to_list()\")\n",
    "print(number_list.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Attribute .unique()\n",
    "\n",
    "Attribute .unique() digunakan menghasilkan nilai unik dari suatu kolom, hasilnya dalam bentuk numpy array. Attribute ini hanya digunakan pada series saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] attribute .unique()\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# [7] attribute .unique()\n",
    "print(\"[7] attribute .unique()\")\n",
    "print(number_list.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Attribute .index\n",
    "\n",
    "Attribute .index digunakan untuk mencari index/key dari Series atau Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] attribute .index\n",
      "    Index number_list: RangeIndex(start=0, stop=6, step=1)\n",
      "    Index matrix_list: RangeIndex(start=0, stop=4, step=1)\n"
     ]
    }
   ],
   "source": [
    "# [8] attribute .index\n",
    "print(\"[8] attribute .index\")\n",
    "print(\"    Index number_list:\", number_list.index)\n",
    "print(\"    Index matrix_list:\", matrix_list.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Attribute .columns\n",
    "\n",
    "Attribute .columns digunakan untuk mengetahui apa saja kolom yang tersedia di dataframe tersebut (hanya digunakan untuk dataframe saja). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] attribute .columns\n",
      "    Column matrix_list: RangeIndex(start=0, stop=3, step=1)\n"
     ]
    }
   ],
   "source": [
    "# [9] attribute .columns\n",
    "print(\"[9] attribute .columns\")\n",
    "print(\"    Column matrix_list:\", matrix_list.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Attribute .loc\n",
    "\n",
    "Attribute .loc digunakan slice dataframe atau series berdasarkan nama kolom dan/atau nama index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] attribute .loc\n",
      "    .loc[0:1] pada number_list: 0    1\n",
      "1    2\n",
      "dtype: int64\n",
      "    .loc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n"
     ]
    }
   ],
   "source": [
    "# [10] attribute .loc\n",
    "print(\"[10] attribute .loc\")\n",
    "print(\"    .loc[0:1] pada number_list:\", number_list.loc[0:1])\n",
    "print(\"    .loc[0:1] pada matrix_list:\", matrix_list.loc[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Attribute .iloc\n",
    "\n",
    "Attribute .iloc digunakan untuk slice dataframe atau series berdasarkan index kolom dan/atau index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] attribute .iloc\n",
      "    iloc[0:1] pada number_list: 0    1\n",
      "dtype: int64\n",
      "    iloc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n"
     ]
    }
   ],
   "source": [
    "# [11] attribute .iloc\n",
    "print(\"[11] attribute .iloc\")\n",
    "print(\"    iloc[0:1] pada number_list:\", number_list.iloc[0:1])\n",
    "print(\"    iloc[0:1] pada matrix_list:\", matrix_list.iloc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    c\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_list.iloc[0:2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from List\n",
    "Untuk membuat Series atau Dataframe bisa dari berbagai macam tipe data container/mapping di python, seperti list dan dictionary, maupun dari numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    1\n",
      "2    3\n",
      "3    5\n",
      "4    c\n",
      "5    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating series from list\n",
    "ex_list = ['a',1,3,5,'c','d']\n",
    "ex_series = pd.Series(ex_list)\n",
    "print(ex_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     float char   obj char\n",
      "dq     1.0    a     b    c\n",
      "lab    2.5    d     e    f\n",
      "kar    5.0    g     h    i\n",
      "lan    7.5    j  10.5    l\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe from list of list\n",
    "ex_list_of_list = [[1 ,'a','b' ,'c'],\n",
    "                   [2.5,'d','e' ,'f'],\n",
    "\t\t           [5 ,'g','h' ,'i'],\n",
    "\t\t           [7.5,'j',10.5,'l']]\n",
    "index = ['dq','lab','kar','lan']\n",
    "cols = ['float','char','obj','char']\n",
    "ex_df = pd.DataFrame(ex_list_of_list, index=index, columns=cols)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Dictionary\n",
    "Untuk membuat Series atau Dataframe bisa dari berbagai macam tipe data container/mapping di python, seperti list dan dictionary, maupun dari numpy array.\n",
    "\n",
    " \n",
    "\n",
    "Pada sub bagian ini, akan membuat Series dan Dataframe yang bersumber dari dictionary. Sekedar meninjau bahwa, dictionary merupakan kumpulan data yang strukturnya terdiri dari key dan value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    a\n",
      "2    b\n",
      "3    c\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating series from dictionary\n",
    "dict_series = {'1':'a',\n",
    "             '2':'b',\n",
    "             '3':'c'}\n",
    "ex_series = pd.Series(dict_series)\n",
    "print(ex_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  4\n",
      "0  a  b  2\n",
      "1  b  c  3\n",
      "2  c  d  z\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe from dictionary\n",
    "df_series = {'1':['a','b','c'],\n",
    "             '2':['b','c','d'],\n",
    "             '4':[2,3,'z']}\n",
    "ex_df = pd.DataFrame(df_series)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Numpy Array\n",
    "Untuk membuat Series atau Dataframe bisa dari berbagai macam tipe data container/mapping di python, seperti list dan dictionary, maupun dari numpy array.\n",
    "\n",
    " \n",
    "\n",
    "Pada sub bagian ini, akan membuat Series dan Dataframe yang bersumber dari numpy array. Sekedar meninjau bahwa, numpy array kumpulan data yang terdiri atas berbagai macam tipe data, mutable, tapi dibungkus dalam array oleh library Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "6    6\n",
      "7    7\n",
      "dtype: int32\n",
      "   0  1  2   3\n",
      "0  1  2  3   5\n",
      "1  5  6  7   8\n",
      "2  a  b  c  10\n"
     ]
    }
   ],
   "source": [
    "# Creating series from numpy array (1D)\n",
    "arr_series = np.array([1,2,3,4,5,6,6,7])\n",
    "ex_series = pd.Series(arr_series)\n",
    "print(ex_series)\n",
    "# Creating dataframe from numpy array (2D)\n",
    "arr_df = np.array([[1 ,2 ,3 ,5],\n",
    "                   [5 ,6 ,7 ,8],\n",
    "                   ['a','b','c',10]])\n",
    "ex_df = pd.DataFrame(arr_df)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset I/O\n",
    "\n",
    "## Read Dataset - CSV dan TSV\n",
    "CSV dan TSV pada hakikatnya adalah tipe data text dengan perbedaan terletak pada pemisah antar data dalam satu baris. Pada file CSV, antar data dalam satu baris dipisahkan oleh comma, \",\". Namun, pada file TSV antar data dalam satu baris dipisahkan oleh \"Tab\".\n",
    "\n",
    "Fungsi .read_csv() digunakan untuk membaca file yang value nya dipisahkan oleh comma (default), terkadang pemisah value nya bisa di set ‘\\t’ untuk file tsv (tab separated values).\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset csv : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\n",
    "\n",
    "Dataset tsv : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n"
     ]
    }
   ],
   "source": [
    "# File CSV\n",
    "df_csv = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "print(df_csv.head(3)) # Menampilkan 3 data teratas\n",
    "# File TSV\n",
    "df_tsv = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv\", sep=\"\\t\")\n",
    "print(df_tsv.head(3)) # Menampilkan 3 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - Excel\n",
    "File Excel dengan ekstensi *.xls atau *.xlsx cukup banyak digunakan dalam menyimpan data. Pandas juga memiliki fitur untuk membaca file excel.\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_excel.xlsx\n",
    "\n",
    "Fungsi .read_excel() digunakan untuk membaca file excel menjadi dataframe pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-918edcd17eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# File xlsx dengan data di sheet \"test\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_excel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_excel.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_excel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Menampilkan 4 data teratas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\latihanpy\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 )\n\u001b[0;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\latihanpy\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\.conda\\envs\\latihanpy\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\latihanpy\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \"\"\"\n\u001b[0;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\latihanpy\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "# File xlsx dengan data di sheet \"test\"\n",
    "df_excel = pd.read_excel(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_excel.xlsx\", sheet_name=\"test\")\n",
    "print(df_excel.head(4)) # Menampilkan 4 data teratas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - JSON\n",
    "Method .read_json() digunakan untuk membaca URL API yang formatnya JSON dan merubahnya menjadi dataframe pandas. \n",
    "\n",
    "Dataset JSON: https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/covid2019-api-herokuapp-v2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# File JSON\n",
    "url = \"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/covid2019-api-herokuapp-v2.json\"\n",
    "df_json = pd.read_json(url)\n",
    "print(df_json.head(10)) # Menampilkan 10 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head & Tail\n",
    "Seperti yang telah dipelajari sebelumnya bahwa ada method .head yang diterapkan pada suatu variabel bertipe pandas dataframe/series.\n",
    "\n",
    "Method .head ditujukan untuk membatasi tampilan jumlah baris teratas dari dataset. Sementara itu, method .tail ditujukan untuk membatasi jumlah baris terbawah dari dataset.\n",
    "\n",
    "Secara umum kedua method ini memiliki bentuk\n",
    "\n",
    "[nama_dataframe].head(n) \n",
    "\n",
    "dan \n",
    "\n",
    "[nama_dataframe].tail(n)\n",
    "\n",
    "dengan n merupakan jumlah baris yang akan ditampilkan, jika tidak disebutkan n = 5 (sebagai nilai default dari n). \n",
    "\n",
    " \n",
    "\n",
    "Tugas Praktek:\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Tampilkan 3 data teratas\n",
    "print(\"Tiga data teratas:\\n\", df.head(3))\n",
    "# Tampilkan 3 data terbawah\n",
    "print(\"Tiga data terbawah:\\n\", df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, dan Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - Part 1\n",
    "Index merupakan key identifier dari tiap row/column untuk Series atau Dataframe (sifatnya tidak mutable untuk masing-masing value tapi bisa diganti untuk semua value sekaligus).\n",
    "\n",
    "Jika tidak disediakan, pandas akan membuat kolom index default secara otomatis sebagai bilangan bulat (integer) dari 0 sampai range jumlah baris data tersebut.\n",
    "\n",
    "Kolom index dapat terdiri dari\n",
    "\n",
    "satu kolom (single index), atau\n",
    "multiple kolom (disebut dengan hierarchical indexing).\n",
    "Index dengan multiple kolom ini terjadi karena unique identifier tidak dapat dicapai hanya dengan set index di 1 kolom saja sehingga membutuhkan beberapa kolom yang menjadikan tiap row menjadi unique.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - Part 2\n",
    "Secara default setelah suatu data frame dibaca dari file dengan format tertentu, index-nya merupakan single index.\n",
    "\n",
    "Pada sub bab ini akan mencetak index dan kolom yang dimiliki oleh file \"sample_csv.csv\". Untuk menentukan index dan kolom yang dimiliki oleh dataset yang telah dinyatakan sebagai sebuah dataframe pandas dapat dilakukan dengan menggunakan attribut .index dan .columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Index dari df\n",
    "print(\"Index:\", df.index)\n",
    "# Column dari df\n",
    "print(\"Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - Part 3\n",
    "Di sub bab sebelumnya telah dibahas terkait single index, tentunya pada sub bab ini akan bahas multi index atau disebut juga dengan hierarchical indexing.\n",
    "\n",
    "Untuk membuat multi index (hierarchical indexing) dengan pandas diperlukan kolom-kolom mana saja yang perlu disusun agar index dari data frame menjadi sebuah hirarki yang kemudian dapat dikenali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Set multi index df\n",
    "df_x = df.set_index(['order_date', 'city', 'customer_id'])\n",
    "# Print nama dan level dari multi index\n",
    "for name, level in zip(df_x.index.names, df_x.index.levels):\n",
    "    print(name,':',level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - Part 4\n",
    "Terdapat beberapa cara untuk membuat index, salah satunya adalah seperti yang telah dilakukan pada sub bab sebelumnya dengan menggunakan method .set_index().\n",
    "\n",
    "Di sub bab ini akan menggunakan assignment untuk menset index dari suatu data frame. Untuk itu file \"sample_excel.xlsx\" yang digunakan. Perhatikan code berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week = pd.DataFrame({\n",
    "    \"day_number\":[1,2,3,4,5,6,7],\n",
    "    \"week_type\":[\"weekday\" for i in range(5)] +\n",
    "    [\"weekened\" for i in range(2)]\n",
    "})\n",
    "# Definisikan indexnya dan assign\n",
    "df_week.index = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "print(df_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_tsv.tsv untuk 10 baris pertama saja\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv\", sep=\"\\t\", nrows=10)\n",
    "# Cetak data frame awal\n",
    "print(\"Dataframe awal:\\n\", df)\n",
    "# Set index baru\n",
    "df.index = [\"Pesanan ke-\" + str(i) for i in range(1, 11)]\n",
    "# Cetak data frame dengan index baru\n",
    "print(\"Dataframe dengan index baru:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing - Part 5\n",
    "Jika file yang akan dibaca melalu penggunaan library pandas dapat dipreview terlebih dahulu struktur datanya maka melalui fungsi yang ditujukan untuk membaca file dapat diset mana kolom yang akan dijadikan index.\n",
    "\n",
    " \n",
    "\n",
    "Fitur ini telah dimiliki oleh setiap fungsi yang digunakan dalam membaca data dengan pandas, yaitu penggunaan argumen index_col pada fungsi yang dimaksud. Untuk jelasnya dapat diperhatikan pada kode berikut ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_tsv.tsv dan set lah index_col sesuai instruksi\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_tsv.tsv\", sep=\"\\t\", index_col=[\"order_date\",\"order_id\"])\n",
    "# Cetak data frame untuk 8 data teratas\n",
    "print(\"Dataframe:\\n\", df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week = pd.DataFrame({'day_number':[1,2,3,4,5,6,7],\n",
    "                        'week_type':['weekday' for i in range(5)] + ['weekend' for i in range(2)]\n",
    "                       })\n",
    "df_week_ix = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "df_week.index = [df_week_ix, df_week['day_number'].to_list()]\n",
    "df_week.index.names = ['name','num']\n",
    "print(df_week.index.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing - Part 1\n",
    "Seperti artinya slicing adalah cara untuk melakukan filter ke dataframe/series berdasarkan kriteria tertentu dari nilai kolomnya ataupun kriteria index-nya.\n",
    "\n",
    "Terdapat 2 cara paling terkenal untuk slicing dataframe, yaitu dengan menggunakan method .loc dan .iloc pada variabel bertipe pandas DataFrame/Series. Method .iloc ditujukan untuk proses slicing berdasarkan index berupa nilai integer tertentu. Akan tetapi akan lebih sering menggunakan dengan method .loc karena lebih fleksibel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Slice langsung berdasarkan kolom\n",
    "df_slice = df.loc[(df[\"customer_id\"] == \"18055\") &\n",
    "\t\t          (df[\"product_id\"].isin([\"P0029\",\"P0040\",\"P0041\",\"P0116\",\"P0117\"]))\n",
    "\t\t\t\t ]\n",
    "print(\"Slice langsung berdasarkan kolom:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing - Part 2\n",
    "Dalam sub bab sebelumnya telah mempelajari bagaimana menslicing/filtering dataset dengan menggunakan method .loc pada kolom dataset.\n",
    "\n",
    "Sekarang, menerapkan berdasarkan index. Tentu syaratnya adalah dataset sudah dilakukan indexing terlebih dahulu melalui penerapan method .set_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Set index dari df sesuai instruksi\n",
    "df = df.set_index([\"order_date\",\"order_id\",\"product_id\"])\n",
    "# Slice sesuai intruksi\n",
    "df_slice = df.loc[(\"2019-01-01\",1612339,[\"P2154\",\"P2159\"]),:]\n",
    "print(\"Slice df:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming - Part 1\n",
    "Transform adalah ketika mengubah dataset yang ada menjadi entitas baru, dapat dilakukan dengan\n",
    "\n",
    "konversi dari satu data type ke data type yang lain,\n",
    "transpose dataframe\n",
    "atau yang lainnya.\n",
    "Hal yang biasa dilakukan pertama kali setelah data dibaca adalah mengecek tipe data di setiap kolomnya apakah sesuai dengan representasinya. Untuk itu dapat menggunakan attribut .dtypes pada dataframe yang telah kita baca tadi,\n",
    "\n",
    "[nama_dataframe].dtypes \n",
    " \n",
    "\n",
    "Untuk konversi tipe data, secara default system akan mendeteksi data yang tidak bisa di render as date type or numeric type sebagai object yang basically string. Tidak bisa di render oleh system ini karena berbagai hal, mungkin karena formatnya asing dan tidak dikenali oleh python secara umum (misal: date type data → '2019Jan01').\n",
    "\n",
    "Data contoh tersebut tidak bisa di render karena bulannya Jan tidak bisa di translate menjadi in form of number (00-12) dan tidak ada ‘-’ di antara tahun, bulan dan harinya. Jika seluruh data pada kolom di order_date sudah tertulis dalam bentuk 'YYYY-MM-DD' maka ketika dibaca, kolom order_date sudah langsung dinyatakan bertipe data datetime.\n",
    "\n",
    "Untuk merubah kolom date_order yang sebelumnya bertipe object menjadi kolom bertipe datetime, cara pertama yang dapat dilakukan adalah menggunakan\n",
    "\n",
    "pd.to_datetime(argumen) \n",
    "dengan argumen adalah isi kolom dari dataframe yang akan dirubah tipe datanya, misal dalam format umum\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"]\n",
    "Sehingga lengkapnya dapat ditulis sebagai\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = pd.to_datetime(nama_dataframe[\"nama_kolom\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Tampilkan tipe data\n",
    "print(\"Tipe data df:\\n\", df.dtypes)\n",
    "# Ubah tipe data kolom order_date menjadi datetime\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])\n",
    "# Tampilkan tipe data df setelah transformasi\n",
    "print(\"\\nTipe data df setelah transformasi:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming - Part 2\n",
    "Pada sub bab ini akan mengubah tipe data pada kolom dataframe yang telah dibaca menjadi tipe data float (kolom quantity) dan tipe categori (kolom city).\n",
    "\n",
    "Secara umum, untuk merubah ke numerik dapat menggunakan pd.to_numeric(), yaitu\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = pd.to_numeric(nama_dataframe[\"nama_kolom\"], downcast=\"tipe_data_baru\")\n",
    "Sedangkan untuk menjadi suatu kolom yang dapat dinyatakan sebagai kategory dapat menggunakan method .astype() pada dataframe, yaitu\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = nama_dataframe[\"nama_kolom\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Tampilkan tipe data\n",
    "print(\"Tipe data df:\\n\", df.dtypes)\n",
    "# Ubah tipe data kolom quantity menjadi tipe data numerik float\n",
    "df[\"quantity\"] = pd.to_numeric(df[\"quantity\"], downcast=\"float\")\n",
    "# Ubah tipe data kolom city menjadi tipe data category\n",
    "df[\"city\"] = df[\"city\"].astype(\"category\")\n",
    "# Tampilkan tipe data df setelah transformasi\n",
    "print(\"\\nTipe data df setelah transformasi:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming - Part 3\n",
    "Sekarang akan mempelajari teknik/cara berikutnya dalam proses transformasi suatu dataframe. Di sub bab ini akan memakai method .apply() dan .map() pada suatu dataframe.\n",
    "\n",
    " \n",
    "\n",
    "Method .apply() digunakan untuk menerapkan suatu fungsi python (yang dibuat dengan def atau anonymous dengan lambda) pada dataframe/series atau hanya kolom tertentu dari dataframe. \n",
    "\n",
    "Method .map() hanya dapat diterapkan pada series atau dataframe yang diakses satu kolom saja. Method ini digunakan untuk mensubstitusikan suatu nilai ke dalam tiap baris datanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/sample_csv.csv\")\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand awal:\\n\", df[\"brand\"].head())\n",
    "# Gunakan method apply untuk merubah isi kolom menjadi lower case\n",
    "df[\"brand\"] = df[\"brand\"].apply(lambda x: x.lower())\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand setelah apply:\\n\", df[\"brand\"].head())\n",
    "# Gunakan method map untuk mengambil kode brand yaitu karakter terakhirnya\n",
    "df[\"brand\"] = df[\"brand\"].map(lambda x: x[-1])\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand setelah map:\\n\", df[\"brand\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming - Part 4\n",
    "Di sub bab sebelumnya sudah mengetahui bahwa map hanya dapat digunakan untuk pandas series. Pada sub bab ini akan menggunakan method .applymap pada dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number generator, set angka seed menjadi suatu angka, bisa semua angka, supaya hasil random nya selalu sama ketika kita run\n",
    "np.random.seed(1234)\n",
    "# create dataframe 3 baris dan 4 kolom dengan angka random\n",
    "df_tr = pd.DataFrame(np.random.rand(3,5)) \n",
    "# Cetak dataframe\n",
    "print(\"Dataframe:\\n\", df_tr)\n",
    "# Cara 1 dengan tanpa define function awalnya, langsung pake fungsi anonymous lambda x\n",
    "df_tr1 = df_tr.applymap(lambda x: x**2 + 3*x + 2) \n",
    "print(\"\\nDataframe - cara 1:\\n\", df_tr1)\n",
    "# Cara 2 dengan define function \n",
    "def qudratic_fun(x):\n",
    "\treturn x**2 + 3*x + 2\n",
    "df_tr2 = df_tr.applymap(qudratic_fun)\n",
    "print(\"\\nDataframe - cara 2:\\n\", df_tr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspeksi Missing Value\n",
    "Value yang hilang/tidak lengkap dari dataframe akan membuat analisis atau model prediksi yang dibuat menjadi tidak akurat dan mengakibatkan keputusan salah yang diambil. Terdapat beberapa cara untuk mengatasi data yang hilang/tidak lengkap tersebut.\n",
    "\n",
    " \n",
    "\n",
    "Data COVID-19 yang akan digunakan ini diambil dari google big query, tetapi sudah disediakan datasetnya dalam format csv dengan nama \"public data covid19 jhu csse eu.csv\". Ini adalah studi kasus untuk meng-handle missing value. Bagaimanakah langkah-langkahnya?\n",
    "\n",
    "Di pandas data yang hilang umumnya direpresentasikan dengan NaN.\n",
    "\n",
    " \n",
    "\n",
    "Langkah pertama, harus tahu kolom mana yang terdapat data hilang dan berapa banyak dengan cara:\n",
    "\n",
    "Cara 1: menerapkan method .info() pada dataframe yang dapat diikuti dari kode berikut ini\n",
    "\n",
    "Cara 2: mengetahui berapa banyak nilai hilang dari tiap kolom di dataset tersebut dengan menerapkan chaining method pada dataframe yaitu .isna().sum(). Method .isna() digunakan untuk mengecek berapa data yang bernilai NaN dan .sum() menjumlahkannya secara default untuk masing-masing kolom dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baca file \"public data covid19 jhu csse eu.csv\"\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n",
    "# Cetak info dari df\n",
    "print(df.info())\n",
    "# Cetak jumlah missing value di setiap kolom\n",
    "mv = df.isna().sum()\n",
    "print(\"\\nJumlah missing value per kolom:\\n\", mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment untuk Missing Value - Part 1\n",
    "Terdapat beberapa cara untuk mengatasi missing value, antara lain:\n",
    "\n",
    "dibiarkan saja,\n",
    "hapus value itu, atau\n",
    "isi value tersebut dengan value yang lain (biasanya interpolasi, mean, median, etc)\n",
    " \n",
    "\n",
    "Sebelum melakukan action ke missing value pada data covid diatas, sebaiknya tampilkan beberapa row teratas dari dataset itu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hanya kolom combine_key yang keseluruhan barisnya adalah missing value (1000 buah), sementara kolom country_region, date, dan confirmed tidak memiliki missing value. Untuk kolom lainnya terdapat beragam jumlah missing value. Apa yang dapat dilakukan?\n",
    "\n",
    "Untuk memahami mana kolom yang akan ditreatment dengan tiga perlakukan di atas lihat nature dari data terlebih dahulu. Contohnya pada kolom death dan recovered jika ada yang missing value maka kemungkinan terbesarnya adalah tidak ada meninggal atau sembuh pada hari tersebut. \n",
    "\n",
    "Untuk kolom yang seluruhnya missing yaitu combined_key dapat dibuang saja satu kolom itu karena tidak ada data yang dapat diketahui dari kolom tersebut.\n",
    "\n",
    "Sementara, kolom yang lainnya bagaimana? Misal ambil kolom province_stat, missing valuenya dapat terjadi bahwa tidak dilaporkan itu berasal dari daerah mana di negara itu. Dapat mengisi misal dengan string 'unknown' karena tahu kolom tersebut bertipe data string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment untuk Missing Value - Part 2\n",
    "Sekarang dapat menerapkan dua aksi yaitu\n",
    "\n",
    "Membiarkannya saja\n",
    "Mengahapus kolom\n",
    " \n",
    "\n",
    "Treatment pertama (membiarkannya saja) seperti pada kolom confirmed, death, dan recovered. Akan tetapi jika tidak ada yang terkonfirmasi, meninggal dan sembuh sebenarnya dapat menukar value ini dengan angka nol. Meskipun ini lebih make sense dalam representasi datanya, tetapi untuk sub bab ini ketiga kolom tersebut diasumsikan dibiarkan memiliki nilai missing value.\n",
    "\n",
    " \n",
    "\n",
    "Treatment kedua yaitu dengan menghapus kolom, yang mana ini digunakan jika seluruh kolom dari dataset yang dipunyai semua barisnya adalah missing value. Untuk itu dapat menerapkan method .dropna() pada dataframe, bagaimana caranya?\n",
    "\n",
    "nama_dataframe.dropna(axis=1, how=\"all\")\n",
    "Pada method .dropna() ada dua keyword argumen yang harus diisikan yaitu axis dan how. Keyword axis digunakan untuk menentukan arah dataframe yang akan dibuang angka 1 untuk menyatakan kolom (column-based) atau dapat ditulis dalam string \"column\". Jika digunakan angka 0 berarti itu dalam searah index (row-based) atau dapat ditulis dalam string \"index\".\n",
    "\n",
    "Sementara, keyword how digunakan untuk bagaimana cara membuangnya. Opsi yang dapat diterimanya (dalam string) adalah\n",
    "\n",
    " \"all\" artinya jika seluruh data di satu/beberapa kolom atau di satu/beberapa baris adalah missing value.\n",
    "\n",
    "\"any\" artinya jika memiliki 1 saja data yang hilang maka buanglah baris/kolom tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file \"public data covid19 jhu csse eu.csv\"\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n",
    "# Cetak ukuran awal dataframe\n",
    "print(\"Ukuran awal df: %d baris, %d kolom.\" % df.shape)\n",
    "# Drop kolom yang seluruhnya missing value dan cetak ukurannya\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "print(\"Ukuran df setelah buang kolom dengan seluruh data missing: %d baris, %d kolom.\" % df.shape)\n",
    "# Drop baris jika ada satu saja data yang missing dan cetak ukurannya\n",
    "df = df.dropna(axis=0, how=\"any\")\n",
    "print(\"Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: %d baris, %d kolom.\" % df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment untuk Missing Value - Part 3\n",
    "Sekarang, akan melakukan treatment ketiga untuk menghandle missing value pada dataframe. Treatment ini dilakukan dengan cara mengisi missing value dengan nilai lain, yang dapat berupa :\n",
    "\n",
    "nilai statistik seperti mean atau median\n",
    "interpolasi data\n",
    "text tertentu\n",
    " \n",
    "\n",
    "Akan mulai pada kolom yang missing yang tipe datanya adalah berupa object. Kolom tersebut adalah province_state, karena tidak tahu secara persis province_state mana yang dimaksud, bisa menempatkan string \"unknown\" sebagai substitusi missing value. Meskipun keduanya berarti sama-sama tidak tahu tetapi berbeda dalam representasi datanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baca file \"public data covid19 jhu csse eu.csv\"\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n",
    "# Cetak unique value pada kolom province_state\n",
    "print(\"Unique value awal:\\n\", df[\"province_state\"].unique())\n",
    "# Ganti missing value dengan string \"unknown_province_state\"\n",
    "df[\"province_state\"] = df[\"province_state\"].fillna(\"unknown_province_state\")\n",
    "# Cetak kembali unique value pada kolom province_state\n",
    "print(\"Unique value setelah fillna:\\n\", df[\"province_state\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment untuk Missing Value - Part 4\n",
    "Masih melanjutkan bagaimana menghandle missing value tentunya dengan jalan mengganti missing value dengan nilai lainnya. Pada bab sebelumnya telah mengganti kolom bertipe objek dengan sesuatu string/teks.\n",
    "\n",
    "Dalam sub bab ini akan mengganti missing value dengan nilai statistik kolom bersangkutan, baik median atau mean (nilai rata-rata). Misalnya akan menggunakan kolom active. Dengan mengabaikan terlebih dahulu sebaran berdasarkan negara (univariate), jika mengisi dengan nilai rata-rata maka harus melihat terlebih dahulu data apakah memiliki ouliers atau tidak. Jika ada outliers dari data maka menggunakan nilai tengah (median) data adalah cara yang lebih safe.\n",
    "\n",
    "Untuk itu diputuskan dengan mengecek nilai median dan nilai mean kolom active juga nilai min dan max-nya. Jika data pada kolom active terdistribusi normal maka nilai mean dan median akan hampir sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat data memiliki distribusi yang skewness, karena nilai mean dan median yang cukup jauh serta range data yang cukup lebar. Di sini pada kolom active data memiliki outliers. Jadi akan mengisi missing value dengan median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\"\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/CHAPTER+4+-+missing+value+-+public+data+covid19+.csv\")\n",
    "# Cetak nilai mean dan median awal\n",
    "print(\"Awal: mean = %f, median = %f.\" % (df[\"active\"].mean(), df[\"active\"].median()))\n",
    "# Isi missing value kolom active dengan median\n",
    "df_median = df[\"active\"].fillna(df[\"active\"].median())\n",
    "# Cetak nilai mean dan median awal setelah diisi dengan median\n",
    "print(\"Fillna median: mean = %f, median = %f.\" % (df_median.mean(), df_median.median()))\n",
    "# Isi missing value kolom active dengan mean\n",
    "df_mean = df[\"active\"].fillna(df[\"active\"].mean())\n",
    "# Cetak nilai mean dan median awal setelah diisi dengan mean\n",
    "print(\"Fillna mean: mean = %f, median = %f.\" % (df_mean.mean(), df_mean.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment untuk Missing Value - Part 5\n",
    "Di bagian ini akan menggunakan teknik interpolasi dalam mengisi nilai missing value pada suatu dataset.\n",
    "\n",
    "Data yang menggunakan interpolasi untuk mengisi data yang hilang adalah time series data, yang secara default akan diisi dengan interpolasi linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "ts = pd.Series({\n",
    "   \"2020-01-01\":9,\n",
    "   \"2020-01-02\":np.nan,\n",
    "   \"2020-01-05\":np.nan,\n",
    "   \"2020-01-07\":24,\n",
    "   \"2020-01-10\":np.nan,\n",
    "   \"2020-01-12\":np.nan,\n",
    "   \"2020-01-15\":33,\n",
    "   \"2020-01-17\":np.nan,\n",
    "   \"2020-01-16\":40,\n",
    "   \"2020-01-20\":45,\n",
    "   \"2020-01-22\":52,\n",
    "   \"2020-01-25\":75,\n",
    "   \"2020-01-28\":np.nan,\n",
    "   \"2020-01-30\":np.nan\n",
    "})\n",
    "print(\"Awal:\\n\", ts)\n",
    "# Isi missing value menggunakan interpolasi linier\n",
    "ts = ts.interpolate()\n",
    "# Cetak time series setelah interpolasi linier\n",
    "print(\"Setelah diisi missing valuenya:\\n\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Project\n",
    "\n",
    "Diberikan dataset ‘retail_raw_test.csv’\n",
    "\n",
    "1. Baca dataset\n",
    "2. Tipe data diubah menjadi tipe yang seharusnya\n",
    "    - customer_id dari string ke int64,\n",
    "    - quantity dari string ke int64,\n",
    "    - item_price dari string ke int64\n",
    "3. transform product_value supaya bentuknya seragam dengan format PXXXX, assign ke kolom baru \"product_id\", dan drop kolom \"product_value\", jika terdapat nan gantilah dengan \"unknown\".\n",
    "4. tranform order_date menjadi value dengan format YYYY-mm-dd\n",
    "5. cek data hilang dari tiap kolom dan kemudian isi missing value\n",
    "    - di brand dengan \"no_brand\", dan\n",
    "    - cek dulu bagaimana missing value di city & province - isi missing value di city dan province dengan \"unknown\"\n",
    "6. create column city/province dari gabungan city & province\n",
    "7. membuat index berdasarkan city_provice, order_date, customer_id, order_id, product_id (cek index)\n",
    "8. membuat kolom \"total_price\" sebagai hasil perkalian quantity dengan item_price\n",
    "9. slice data hanya untuk Jan 2019\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset : https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/retail_raw_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Baca dataset\n",
    "print(\"[1] BACA DATASET\")\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/retail_raw_test.csv\", low_memory=False)\n",
    "print(\"    Dataset:\\n\", df.head())\n",
    "print(\"    Info:\\n\", df.info())\n",
    "\n",
    "# 2. Ubah tipe data\n",
    "print(\"\\n[2] UBAH TIPE DATA\")\n",
    "df[\"customer_id\"] = df[\"customer_id\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "df[\"quantity\"] = df[\"quantity\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "df[\"item_price\"] = df[\"item_price\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "print(\"    Tipe data:\\n\", df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] BACA DATASET\n",
      " Dataset:\n",
      "    order_id    order_date customer_id           city     province    brand  \\\n",
      "0   1730350  Dec 11, 2019      '13447      Surakarta  Jawa Tengah  BRAND_F   \n",
      "1   1677490  Jul 31, 2019          '0            NaN          NaN  BRAND_F   \n",
      "2   1704211  Oct 18, 2019      '16128  Jakarta Pusat  DKI Jakarta  BRAND_H   \n",
      "3   1679695  Aug 07, 2019      '16225     Yogyakarta   Yogyakarta  BRAND_H   \n",
      "4   1679080  Aug 05, 2019          '0            NaN          NaN  BRAND_E   \n",
      "\n",
      "  quantity item_price  product_value  \n",
      "0      '24    '113000         1374.0  \n",
      "1       '1   '1164000         1370.0  \n",
      "2      '12    '747000         1679.0  \n",
      "3       '6    '590000         1708.0  \n",
      "4       '2    '740000         1201.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       5000 non-null   int64  \n",
      " 1   order_date     5000 non-null   object \n",
      " 2   customer_id    5000 non-null   object \n",
      " 3   city           3802 non-null   object \n",
      " 4   province       3802 non-null   object \n",
      " 5   brand          4995 non-null   object \n",
      " 6   quantity       5000 non-null   object \n",
      " 7   item_price     5000 non-null   object \n",
      " 8   product_value  4995 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 351.7+ KB\n",
      " Info:\n",
      " None\n",
      "\n",
      "[2] UBAH TIPE DATA\n",
      " Tipe data:\n",
      " order_id           int64\n",
      "order_date        object\n",
      "customer_id        int64\n",
      "city              object\n",
      "province          object\n",
      "brand             object\n",
      "quantity           int64\n",
      "item_price         int64\n",
      "product_value    float64\n",
      "dtype: object\n",
      "\n",
      "[3] TRANSFORM product_value MENJADI product_id\n",
      "   order_id    order_date  customer_id           city     province    brand  \\\n",
      "0   1730350  Dec 11, 2019        13447      Surakarta  Jawa Tengah  BRAND_F   \n",
      "1   1677490  Jul 31, 2019            0            NaN          NaN  BRAND_F   \n",
      "2   1704211  Oct 18, 2019        16128  Jakarta Pusat  DKI Jakarta  BRAND_H   \n",
      "3   1679695  Aug 07, 2019        16225     Yogyakarta   Yogyakarta  BRAND_H   \n",
      "4   1679080  Aug 05, 2019            0            NaN          NaN  BRAND_E   \n",
      "\n",
      "   quantity  item_price product_id  \n",
      "0        24      113000      P1374  \n",
      "1         1     1164000      P1370  \n",
      "2        12      747000      P1679  \n",
      "3         6      590000      P1708  \n",
      "4         2      740000      P1201  \n",
      "\n",
      "[4] TRANSFORM order_date MENJADI FORMAT YYYY-mm-dd\n",
      " Tipe data:\n",
      " order_id                int64\n",
      "order_date     datetime64[ns]\n",
      "customer_id             int64\n",
      "city                   object\n",
      "province               object\n",
      "brand                  object\n",
      "quantity                int64\n",
      "item_price              int64\n",
      "product_id             object\n",
      "dtype: object\n",
      "\n",
      "[5] HANDLING MISSING VALUE\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   order_id     5000 non-null   int64         \n",
      " 1   order_date   5000 non-null   datetime64[ns]\n",
      " 2   customer_id  5000 non-null   int64         \n",
      " 3   city         5000 non-null   object        \n",
      " 4   province     5000 non-null   object        \n",
      " 5   brand        5000 non-null   object        \n",
      " 6   quantity     5000 non-null   int64         \n",
      " 7   item_price   5000 non-null   int64         \n",
      " 8   product_id   5000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 351.7+ KB\n",
      " Info:\n",
      " None\n",
      "\n",
      "[6] MEMBUAT KOLOM BARU city/province\n",
      "   order_id order_date  customer_id    brand  quantity  item_price product_id  \\\n",
      "0   1730350 2019-12-11        13447  BRAND_F        24      113000      P1374   \n",
      "1   1677490 2019-07-31            0  BRAND_F         1     1164000      P1370   \n",
      "2   1704211 2019-10-18        16128  BRAND_H        12      747000      P1679   \n",
      "3   1679695 2019-08-07        16225  BRAND_H         6      590000      P1708   \n",
      "4   1679080 2019-08-05            0  BRAND_E         2      740000      P1201   \n",
      "\n",
      "               city/province  \n",
      "0      Surakarta/Jawa Tengah  \n",
      "1            unknown/unknown  \n",
      "2  Jakarta Pusat/DKI Jakarta  \n",
      "3      Yogyakarta/Yogyakarta  \n",
      "4            unknown/unknown  \n",
      "\n",
      "[7] MEMBUAT HIERACHICAL INDEX\n",
      "                                                                     brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936       BRAND_K   \n",
      "                       2019-11-12 12360       1715116  P0758       BRAND_C   \n",
      "                                                       P3042       BRAND_R   \n",
      "                       2019-12-09 12374       1729036  P1660       BRAND_G   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936             24   \n",
      "                       2019-11-12 12360       1715116  P0758              8   \n",
      "                                                       P3042             12   \n",
      "                       2019-12-09 12374       1729036  P1660              4   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "\n",
      "                                                                   item_price  \n",
      "city/province          order_date customer_id order_id product_id              \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936           450000  \n",
      "                       2019-11-12 12360       1715116  P0758           695000  \n",
      "                                                       P3042           310000  \n",
      "                       2019-12-09 12374       1729036  P1660          2795000  \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000  \n",
      "\n",
      "[8] MEMBUAT KOLOM total_price\n",
      "                                                                     brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936       BRAND_K   \n",
      "                       2019-11-12 12360       1715116  P0758       BRAND_C   \n",
      "                                                       P3042       BRAND_R   \n",
      "                       2019-12-09 12374       1729036  P1660       BRAND_G   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936             24   \n",
      "                       2019-11-12 12360       1715116  P0758              8   \n",
      "                                                       P3042             12   \n",
      "                       2019-12-09 12374       1729036  P1660              4   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "\n",
      "                                                                   item_price  \\\n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936           450000   \n",
      "                       2019-11-12 12360       1715116  P0758           695000   \n",
      "                                                       P3042           310000   \n",
      "                       2019-12-09 12374       1729036  P1660          2795000   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000   \n",
      "\n",
      "                                                                   total_price  \n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936          10800000  \n",
      "                       2019-11-12 12360       1715116  P0758           5560000  \n",
      "                                                       P3042           3720000  \n",
      "                       2019-12-09 12374       1729036  P1660          11180000  \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           8340000  \n",
      "\n",
      "[9] SLICE DATASET UNTUK BULAN JANUARI 2019 SAJA\n",
      "Dataset akhir:\n",
      "                                                                      brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597       BRAND_G   \n",
      "                       2019-01-10 17392       1617952  P2137       BRAND_M   \n",
      "                       2019-01-14 15527       1618828  P3115       BRAND_S   \n",
      "                       2019-01-29 13253       1620289  P0099       BRAND_A   \n",
      "...                                                                    ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070       BRAND_R   \n",
      "                                                       P3483       BRAND_S   \n",
      "                       2019-01-31 0           1621057  P1298       BRAND_F   \n",
      "                                                       P1773       BRAND_H   \n",
      "                                                       P2877       BRAND_R   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597              9   \n",
      "                       2019-01-10 17392       1617952  P2137              2   \n",
      "                       2019-01-14 15527       1618828  P3115              1   \n",
      "                       2019-01-29 13253       1620289  P0099             12   \n",
      "...                                                                     ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070              1   \n",
      "                                                       P3483              3   \n",
      "                       2019-01-31 0           1621057  P1298              1   \n",
      "                                                       P1773              5   \n",
      "                                                       P2877              1   \n",
      "\n",
      "                                                                   item_price  \\\n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597           520000   \n",
      "                       2019-01-10 17392       1617952  P2137          1062000   \n",
      "                       2019-01-14 15527       1618828  P3115          1045000   \n",
      "                       2019-01-29 13253       1620289  P0099           450000   \n",
      "...                                                                       ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070           593000   \n",
      "                                                       P3483           593000   \n",
      "                       2019-01-31 0           1621057  P1298           296000   \n",
      "                                                       P1773           593000   \n",
      "                                                       P2877          1486000   \n",
      "\n",
      "                                                                   total_price  \n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           8340000  \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597           4680000  \n",
      "                       2019-01-10 17392       1617952  P2137           2124000  \n",
      "                       2019-01-14 15527       1618828  P3115           1045000  \n",
      "                       2019-01-29 13253       1620289  P0099           5400000  \n",
      "...                                                                        ...  \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070            593000  \n",
      "                                                       P3483           1779000  \n",
      "                       2019-01-31 0           1621057  P1298            296000  \n",
      "                                                       P1773           2965000  \n",
      "                                                       P2877           1486000  \n",
      "\n",
      "[334 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 1. Baca dataset\n",
    "print(\"[1] BACA DATASET\")\n",
    "df = pd.read_csv(\"https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/retail_raw_test.csv\", low_memory=False)\n",
    "print(\" Dataset:\\n\", df.head())\n",
    "print(\" Info:\\n\", df.info())\n",
    "\n",
    "# 2. Ubah tipe data\n",
    "print(\"\\n[2] UBAH TIPE DATA\")\n",
    "df[\"customer_id\"] = df[\"customer_id\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "df[\"quantity\"] = df[\"quantity\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "df[\"item_price\"] = df[\"item_price\"].apply(lambda x: x.split(\"'\")[1]).astype(\"int64\")\n",
    "print(\" Tipe data:\\n\", df.dtypes)\n",
    "\n",
    "# 3. Transform \"product_value\" supaya bentuknya seragam dengan format \"PXXXX\", assign ke kolom baru \"product_id\", dan drop kolom \"product_value\", jika terdapat nan gantilah dengan \"unknown\"\n",
    "print(\"\\n[3] TRANSFORM product_value MENJADI product_id\")\n",
    "# Buat fungsi\n",
    "import math\n",
    "def impute_product_value(val):\n",
    "    if math.isnan(val):\n",
    "        return \"unknown\"\n",
    "    else:\n",
    "        return 'P' + '{:0>4}'.format(str(val).split('.')[0])\n",
    "# Buat kolom \"product_id\"\n",
    "df[\"product_id\"] = df[\"product_value\"].apply(lambda x: impute_product_value(x))\n",
    "# Hapus kolom \"product_value\"\n",
    "df.drop([\"product_value\"], axis=1, inplace=True)\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 4. Tranform order_date menjadi value dengan format \"YYYY-mm-dd\"\n",
    "print(\"\\n[4] TRANSFORM order_date MENJADI FORMAT YYYY-mm-dd\")\n",
    "months_dict = {\n",
    "\"Jan\":\"01\",\n",
    "\"Feb\":\"02\",\n",
    "\"Mar\":\"03\",\n",
    "\"Apr\":\"04\",\n",
    "\"May\":\"05\",\n",
    "\"Jun\":\"06\",\n",
    "\"Jul\":\"07\",\n",
    "\"Aug\":\"08\",\n",
    "\"Sep\":\"09\",\n",
    "\"Oct\":\"10\",\n",
    "\"Nov\":\"11\",\n",
    "\"Dec\":\"12\"\n",
    "}\n",
    "\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"].apply(lambda x: str(x)[-4:] + \"-\" + months_dict[str(x)[:3]] + \"-\" + str(x)[4:7]))\n",
    "print(\" Tipe data:\\n\", df.dtypes)\n",
    "\n",
    "# 5. Mengatasi data yang hilang di beberapa kolom\n",
    "print(\"\\n[5] HANDLING MISSING VALUE\")\n",
    "# Kolom \"city\" dan \"province\" masih memiliki missing value, nilai yang hilang di kedua kolom ini diisi saja dengan \"unknown\"\n",
    "df[[\"city\",\"province\"]] = df[[\"city\",\"province\"]].fillna(\"unknown\")\n",
    "# Kolom brand juga masih memiliki missing value, Ganti value NaN menjadi \"no_brand\"\n",
    "df[\"brand\"] = df[\"brand\"].fillna(\"no_brand\")\n",
    "# Cek apakah masih terdapat missing value di seluruh kolom\n",
    "print(\" Info:\\n\", df.info())\n",
    "\n",
    "# 6. Membuat kolom baru \"city/province\" dengan menggabungkan kolom \"city\" dan kolom \"province\" dan delete kolom asalnya\n",
    "print(\"\\n[6] MEMBUAT KOLOM BARU city/province\")\n",
    "df[\"city/province\"] = df[\"city\"] + \"/\" + df[\"province\"]\n",
    "# drop kolom \"city\" dan \"province\" karena telah digabungkan\n",
    "df.drop([\"city\",\"province\"], axis=1, inplace=True)\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 7. Membuat hierarchical index yang terdiri dari kolom \"city/province\", \"order_date\", \"customer_id\", \"order_id\", \"product_id\"\n",
    "print(\"\\n[7] MEMBUAT HIERACHICAL INDEX\")\n",
    "df = df.set_index([\"city/province\",\"order_date\",\"customer_id\",\"order_id\",\"product_id\"])\n",
    "# urutkanlah berdasarkan index yang baru\n",
    "df = df.sort_index()\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 8. Membuat kolom \"total_price\" yang formula nya perkalian antara kolom \"quantity\" dan kolom \"item_price\"\n",
    "print(\"\\n[8] MEMBUAT KOLOM total_price\")\n",
    "df[\"total_price\"] = df[\"quantity\"] * df[\"item_price\"]\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 9. Slice dataset agar hanya terdapat data bulan Januari 2019\n",
    "print(\"\\n[9] SLICE DATASET UNTUK BULAN JANUARI 2019 SAJA\")\n",
    "idx = pd.IndexSlice\n",
    "df_jan2019 = df.loc[idx[:, \"2019-01-01\":\"2019-01-31\"], :]\n",
    "print(\"Dataset akhir:\\n\", df_jan2019)\n",
    "\n",
    "# END OF PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
